{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "Practica1_Reconocimiento_Formas.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2-AngM7IWxnf",
        "MHLaQDLZW6xr",
        "dnNZ-i-WXEEw",
        "nZGQSU-GwuSs",
        "s4TjdJyeAk7F",
        "AdoHPJLaNpCh",
        "3-R3UunlNscs"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LaertesPecker/Clasificadores/blob/master/Practica1_Reconocimiento_Formas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nx7EE02AplNp",
        "colab_type": "text"
      },
      "source": [
        "# PRÁCTICA 1: Clasificadores Euclídeo y Bayesiano\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiRCjRQSplNt",
        "colab_type": "text"
      },
      "source": [
        "## 1. Introducción\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-AngM7IWxnf",
        "colab_type": "text"
      },
      "source": [
        "## 2. Clasificador de la distancia euclídea"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHLaQDLZW6xr",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 En qué consiste el clasificador y como lo hemos implementado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8WfsMIjplNw",
        "colab_type": "text"
      },
      "source": [
        "El clasificador de la distancia euclídea parte de la hipótesis de que dispersion de las clases es pequeña en relación a la distancia entre ellas. Una vez aceptada la hipótesis, el representante de cada clase será el centroide de todos los datos pertenecientes a esa clase. Por tanto, el primer paso para impementar en clasificador será calcular los centroides de los datos de test. Una vez calculados los centroides, para determinar la pertenencia de un dato a una clase, calcularemos la distancia del dato a todos los centroides y el dato pertenecerá a la clase que representa el centroide más cercano a él. \n",
        "\n",
        "Matemáticamente, el cálculo del centroide es: $z_i = \\frac{1}{card(\\alpha_i)}\\sum_{x \\in \\alpha_i} x$, donde $\\alpha_i$ representa a la clase i. Como ya se ha expuesto arriba, la función discriminante será la distancia euclídea $f_i(x)=d_E(x,z_i)$. Por tanto, se clasificará un objeto en la clase cuya distancia\n",
        "sea la mínima, es decir $x \\in \\alpha_i \\leftrightarrow arg min_i{f_i(x)}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnNZ-i-WXEEw",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 Implementación del clasificador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPEH8KHRW2bm",
        "colab_type": "text"
      },
      "source": [
        "Para implementar el clasificador se deberán definir 4 funciones: La función de **fit**, la cual calculará los centroides de nuestros datos de test. La función **predict**, la cual calculará la distancia de todos nuestros datos los cuales queremos obtener su clase a todos los centroides calculados en la función fit. La función **pred_label**, que cogerá la etiqueta del centroide mas cercano a todos los datos que queremos predecir. Finalmente, la función **num_aciertos**, que calculará el número de aciertos de nuestro clasificador.\n",
        "\n",
        "Empezamos importando los paquetes necesarios y creando la clase y el constructor de la misma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ezy3rBUmwr6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from abc import abstractmethod\n",
        "\n",
        "class Classifier:\n",
        "    @abstractmethod\n",
        "    def fit(self,X,y):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def predict(self,X):\n",
        "        pass\n",
        "\n",
        "class ClassifEuclid(Classifier):\n",
        "    def __init__(self,labels=[]):\n",
        "        self.labels=labels\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQa1Iu7U7BM_",
        "colab_type": "text"
      },
      "source": [
        "A continuación, definimos la función fit:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w99NNecF7E6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(self,X,y):\n",
        "        self = np.array([np.mean(X[y==l],axis=0) for l in np.unique(y)])\n",
        "        return self"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKjKaH8f7RBe",
        "colab_type": "text"
      },
      "source": [
        "Como se ha descrito arriba, la función fit calcula los centroides, para ello recorre todas las x con misma etiqueta y calcula su media. A continuación se procede a escribir la función predict:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrbJDVVj7eZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(self,X):\n",
        "        distancias = np.linalg.norm(centroides[:,np.newaxis] - X,axis=2)\n",
        "        return distancias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFELkfNJ88aH",
        "colab_type": "text"
      },
      "source": [
        "Calcula la norma entre los centroides y los valores de x, es decir, calcula la distancia euclídea y la almacena en la variable distancias. Hay que añadiendo una nueva columna o hacer un reshape de centroides para poder operar con x, haciendo el reshape para los datos del iris deberíamos cambiar la matriz de centroides con:\n",
        "\n",
        "```\n",
        "centroides.reshape(3,1,4)\n",
        "```\n",
        "Continuamos definiendo la función pred_label:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IXQiusm9VBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pred_label(self,X):\n",
        "        distancias = predict(self,X)\n",
        "        pred = np.argmin(distancias,axis=0)\n",
        "        return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7kDy0_N9sGj",
        "colab_type": "text"
      },
      "source": [
        "Finalmente, calculamos el número de aciertos y el porcentaje de aciertos de nuestro clasificador:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzGncrl99zdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def num_aciertos(self,X,y):\n",
        "        pred = pred_label(self,X)\n",
        "        numAciertos = (pred == y).sum()\n",
        "        porcAciertos = (pred==y).mean()*100\n",
        "        print(f\"Numero de aciertos: {numAciertos} , Porcetaje de Aciertos: {porcAciertos}\" )\n",
        "        return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfz_4SniVA9Z",
        "colab_type": "text"
      },
      "source": [
        "Definimos una función más que utilizaremos cuando queramos utilizar una parte de los datos para entrenar nuestro clasificador, por defecto entrenaremos con el 70% de los datos y testearemos con el otro 30%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjp8wVLGUewB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clasfEucl(X,y,name,test_size=0.3):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
        "  centroides = np.array([np.mean(X_train[y_train==l],axis=0) for l in np.unique(y_train)])\n",
        "  distancias = np.linalg.norm(centroides[:,np.newaxis] - X_test,axis=2)\n",
        "  pred = np.argmin(distancias,axis=0)\n",
        "  numAciertos = (pred == y_test).sum()\n",
        "  porcAciertos = (pred == y_test).mean()*100\n",
        "  print(f\"Datos \" + name + \":\")\n",
        "  print(f\"Numero de aciertos: {numAciertos} , Porcetaje de Aciertos: {porcAciertos}\" )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZGQSU-GwuSs",
        "colab_type": "text"
      },
      "source": [
        "### 2.3 Tabla de resultados. Discusión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KC1hr5LtXO2B",
        "colab_type": "text"
      },
      "source": [
        "Utilizamos nuestro clasificador para los datos de iris, wine y cancer. Para entrenar nuestro clasificador utilizaremos todos los datos y veremos que, aún así, no obtendremos un 100% de porcentaje de aciertos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6LeQF_pS-hw",
        "colab_type": "code",
        "outputId": "19098247-5541-4624-a2f8-80a6b7daeb6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "X, y  = load_iris(return_X_y=True)\n",
        "clasfEucl(X,y,\"Iris\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datos Iris:\n",
            "Numero de aciertos: 42 , Porcetaje de Aciertos: 93.33333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axisYgAYTM7X",
        "colab_type": "code",
        "outputId": "7ec2490a-fb73-46b5-d725-3290b42740f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "X, y  = load_wine(return_X_y=True)\n",
        "clasfEucl(X,y,\"Wine\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datos Wine:\n",
            "Numero de aciertos: 40 , Porcetaje de Aciertos: 74.07407407407408\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbzFmiCBR5Vy",
        "colab_type": "code",
        "outputId": "cc324a7c-6f29-4c3b-d3ab-f775020a6a46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "X, y =load_breast_cancer(return_X_y=True)\n",
        "clasfEucl(X,y,\"Cancer\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datos Cancer:\n",
            "Numero de aciertos: 145 , Porcetaje de Aciertos: 84.7953216374269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qndlNLFNvPn",
        "colab_type": "text"
      },
      "source": [
        "#### 2.3.4 Discusión\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cc4NAogplN0",
        "colab_type": "text"
      },
      "source": [
        "## 3. Clasificador Estadístico Bayesiano\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3KaWBnrfXgp",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 En qué consiste el clasificador y como lo hemos implementado\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wktwuFuHgSIq",
        "colab_type": "text"
      },
      "source": [
        "La medida de pertenencia ahora va a estar establecida por la estadística bayesiana. Cuando usabamos un clasificador euclídeo, la dispersión debía ser pequeña dentro de una clase para que funcionara bien. En este tema vamos a resolver el problema de clasificación mediante el modelado estadístico de la distribución de las muestras en casa clase. Este clasificador solo funcionará bien para clases que se distribuyan unimodalmente. Otro inconveniente de este clasificador es que el número de parámetros crece cuadráticamente. No obstante, este clasificador es muy simple matemáticamente y se adecua a muchos problemas. A menudo, es imposible encontrar una frontera que separe perfectamente dos clases. Vamos a minimizar este error con la estadística.\n",
        "\n",
        "Para nuestro clasificador usaremos la probabilidad a posteriori pero, gracias al teorema de Bayes, conociendo las demás podemos conocer la a posteriori: \n",
        "\n",
        "$P(\\alpha_i|x) = \\frac{p(x|\\alpha_i)P(\\alpha_i)}{p(x)}$\n",
        "\n",
        "Una forma de clasificar, por ejemplo, seria asignarle la que tenga mayor numerador. Por tanto, la funcion discriminante la podremos escribir como:\n",
        "    \n",
        "$f_j(x) = P(\\alpha_j|x)$\n",
        "\n",
        "$f_j(x) = p(\\alpha_j,x) = p(x|\\alpha_j)P(\\alpha_j)$ (conjunta)\n",
        "\n",
        "Ambas son compatibles porque solo difieren en una constante, p(x).\n",
        "\n",
        "Vamos a suponer que la condicionada en cada clase sigue una gausiana normal de media μ. Entrenar nuestro clasificador sera encontrar la media y la variancia para cada clase. En una gausiana, el exponente es parecido a una distancia (si sigma vale uno o es la identidad es una distancia). Una vez calculemos la media, varianza, probabilidad a priori y la inversa de la varianza, sustituiremos los valores en la función discriminante:\n",
        "\n",
        "$d_i(x) = -\\frac{1}{2}ln|\\Sigma_i| - \\frac{1}{2}(x-\\mu_i)^T\\Sigma_i^{-1}(x-\\mu_i) + ln P(\\alpha_i)$\n",
        "\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6k6vchsfcRi",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Implementación del clasificador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM-I0ChMnlwt",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Nuestra función **fit** se encargará de calcular la probabilidad a priori (pues es independiente de X), la matriz de covarianzas y la media de cada clase. Quedando:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP1GK_tHjuj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_estadistico(X,y):\n",
        "  unique, counts = np.unique(y,return_counts=True)\n",
        "  self.labels = unique\n",
        "  prob_priori = np.divide(counts,y.sum())\n",
        "  ln_priori = np.log(prob_priori)\n",
        "  self.ln_apriories = ln_priori\n",
        "  self.means = np.array([np.mean(X[y==l],axis=0) for l in np.unique(y)])\n",
        "  cov = np.array([np.cov(X[y==l] - self.means[l], rowvar=False) for l in np.unique(y)])\n",
        "  det = np.array(np.linalg.det(cov))\n",
        "  self.ln_determinants = np.log(det)\n",
        "  self.inv_covs = np.linalg.inv(cov)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjowipPjkAhX",
        "colab_type": "text"
      },
      "source": [
        "Nuestra función predict, calculará la resta entre las X y las medias y computará la función discriminante:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQqviBM1kIij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_estadistico(X,y):\n",
        "  mean_x0 = np.array(X - media[:,np.newaxis])\n",
        "  j=0\n",
        "  result = np.empty((3,np.shape(X)[0]))\n",
        "  for row in mean_x0:\n",
        "    mult = row.dot(self.inv_covs[j])\n",
        "    mult = (mult*row).sum(1)\n",
        "    mult = mult/-2\n",
        "    result[j] = -0.5*self.ln_determinants[j] + mult + self.ln_apriories[j]\n",
        "    np.vstack(result)\n",
        "    j+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JppJQ9z9ldzn",
        "colab_type": "text"
      },
      "source": [
        "La funcion predict simplemente se quedará con los argumentos máximos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eUUtkcglh5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_label_estadistico(self,X):\n",
        "  pred = np.argmax(result,axis=0)\n",
        "  num_aciertos = (pred == y).sum()\n",
        "  media_aciertos = (pred == y).mean()*100\n",
        "  print(f\"Numero de Aciertos es: {num_aciertos}, Porcentaje de aciertos: {media_aciertos}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fqhJi74lbJx",
        "colab_type": "text"
      },
      "source": [
        "Quedando la clase completa como:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybEYikMJkVCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from abc import abstractmethod\n",
        "\n",
        "class Classifier:\n",
        "\n",
        "    @abstractmethod\n",
        "    def fit(self,X,y):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def predict(self,X):\n",
        "        pass\n",
        "\n",
        "class ClassifBayesiano(Classifier):\n",
        "    def __init__(self):\n",
        "        \"\"\"Constructor de la clase\n",
        "        labels: lista de etiquetas de esta clase\"\"\"\n",
        "        self.ln_apriories = None\n",
        "        self.means = None\n",
        "        self.ln_determinants = None\n",
        "        self.inv_covs = None\n",
        "    def fit_estadistico(self,X,y):\n",
        "        assert X.ndim == 2 and X.shape[0] == len(y)\n",
        "        unique, counts = np.unique(y,return_counts=True)\n",
        "        self.labels = unique\n",
        "        prob_priori = np.divide(counts,y.sum())\n",
        "        ln_priori = np.log(prob_priori)\n",
        "        self.ln_apriories = ln_priori\n",
        "        self.means = np.array([np.mean(X[y==l],axis=0) for l in np.unique(y)])\n",
        "        cov = np.array([np.cov(X[y==l] - self.means[l], rowvar=False) for l in np.unique(y)])\n",
        "        det = np.array(np.linalg.det(cov))\n",
        "        self.ln_determinants = np.log(det)\n",
        "        self.inv_covs = np.linalg.inv(cov)\n",
        "        return self\n",
        "    def predict_estadistico(self,X):\n",
        "        assert self.means is not None, \"Error: The classifier needs to be fitted. Please call fit(X, y) method.\"\n",
        "        assert X.ndim == 2 and X.shape[1] == self.means.shape[1]\n",
        "        mean_x0 = np.array(X - self.means[:,np.newaxis])\n",
        "        j=0\n",
        "        result = np.empty((3,np.shape(X)[0]))\n",
        "        for row in mean_x0:\n",
        "          mult = row.dot(self.inv_covs[j])\n",
        "          mult = (mult*row).sum(1)\n",
        "          mult = mult/-2   \n",
        "          result[j] = -0.5*self.ln_determinants[j] + mult + self.ln_apriories[j]\n",
        "          np.vstack(result)\n",
        "          j+=1\n",
        "        return result\n",
        "    def predict_label_estadistico(self,y,grado_pertenencia):\n",
        "        pred = np.argmax(grado_pertenencia,axis=0)\n",
        "        num_aciertos = (pred == y).sum()\n",
        "        media_aciertos = (pred == y).mean()*100\n",
        "        print(f\"Numero de Aciertos es: {num_aciertos}, Porcentaje de aciertos: {media_aciertos}\")\n",
        "    def clasfBay(X,y,test_size=0.3):\n",
        "      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
        "      clasfXBayesiano = ClassifBayesiano()\n",
        "      clasfXBayesiano.fit_estadistico(X_train,y_train)\n",
        "      grado = clasfXBayesiano.predict_estadistico(X_test)\n",
        "      clasfXBayesiano.predict_label_estadistico(y_test,grado)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v15yk3XCfgfG",
        "colab_type": "text"
      },
      "source": [
        "### 3.3 Tabla de resultados. Discusión y comparadlos con el de distancia euclidea"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSTHBR1Ln7DI",
        "colab_type": "text"
      },
      "source": [
        "Cogiendo una muestra de test del 50% obtenemos los siguientes resultados para los tres datasets estudiados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0GOrUVgqlgp",
        "colab_type": "code",
        "outputId": "b88109b9-e997-4742-b9ec-ea0e6e1ed611",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from sklearn.datasets import load_iris, load_breast_cancer, load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "X, y  = load_iris(return_X_y=True)\n",
        "print(\"Datos Iris Bayesiano:\")\n",
        "ClassifBayesiano.clasfBay(X,y,0.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datos Iris Bayesiano:\n",
            "Numero de Aciertos es: 73, Porcentaje de aciertos: 97.33333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sStHIEt6op5L",
        "colab_type": "code",
        "outputId": "829f2d8f-eb84-4647-acfd-27665de26f00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "X, y  = load_wine(return_X_y=True)\n",
        "print(\"Datos Wine Bayesiano:\")\n",
        "ClassifBayesiano.clasfBay(X,y,0.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datos Wine Bayesiano:\n",
            "Numero de Aciertos es: 85, Porcentaje de aciertos: 95.50561797752809\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUzsfYqHowJ7",
        "colab_type": "code",
        "outputId": "1fb60124-ba18-4711-f6cc-93e5b2239dae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "X, y  = load_breast_cancer(return_X_y=True)\n",
        "print(\"Datos Cancer Bayesiano:\")\n",
        "ClassifBayesiano.clasfBay(X,y,0.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datos Cancer Bayesiano:\n",
            "Numero de Aciertos es: 259, Porcentaje de aciertos: 90.87719298245615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvwKgN1_plN3",
        "colab_type": "text"
      },
      "source": [
        "## 4. Regularización\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGSXd5vrf50I",
        "colab_type": "text"
      },
      "source": [
        "### 4.1 Explica brevemente en qué consiste la regularización y justifica su necesidad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv88wnwngApo",
        "colab_type": "text"
      },
      "source": [
        "### 4.1 Implementa el clasificador Estadístico Bayesiano Paramétrico"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzFeDOhlplN9",
        "colab_type": "text"
      },
      "source": [
        "## Evaluación del Rendimiento\n",
        "\n",
        "Empleando el código de soporte que se ha proporcionado en los esqueletos de las prácticas parciales, entrenay evalúa el rendimiento de los clasificadores de la distancia euclídea y del clasificador estadístico bayesiano con regularización, empleando validación cruzada k-fold, en las bases de datos de Iris, Wine y Cancer. Compara los resultados con los obtenidos en las secciones anteriores y discute las diferencias.Empleando el código de soporte que se ha proporcionado en los esqueletos de las prácticas parciales, entrena, encontrando los parámetros de regularización que obtienen el mejor rendimiento para el clasificador bayesiano paramétrico, y evalúa el rendimiento de los clasificadores de la distancia euclídea y del clasificador bayesiano paramétrico, empleando el método de exclusión en las bases de datos MNIST e Isolet.Compara los resultados con los obtenidos en las secciones anteriores y discute las diferencias.Para entrenar un clasificador y hacer una correcta evaluación de su rendimiento es necesario que el conjunto de datos que se utiliza para evaluación (conjunto de test) no se haya utilizado en ninguna etapa del entrenamiento. En caso contrario estaríamos sobre-ajustando a dicho conjunto de test. En este apartado, para simplificar el proceso se os ha propuesto entrenar y seleccionar los parámetros de regularización empleando un método wrapper que optimizase el rendimiento del conjunto de test. Razona por qué esta estimación del rendimiento está sesgada y qué habría que hacer para obtener una estimación más ajustada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmMn9SajplN_",
        "colab_type": "text"
      },
      "source": [
        "## Aplicación en un caso real de reconocimiento de texto\n",
        "\n",
        "Emplea los clasificadores construidos en el apartado anterior para crear un programa capaz de reconocer el texto presente en una hoja de texto escaneada como la que se puede encontrar en el fichero “EJEMPLO_PRACTICA6.JPG” de la práctica 6. Puedes emplear todo el código de soporte de la Práctica 6, si así lo deseas. Describe el proceso de análisis que has seguido para mejorar tus resultados respecto a los resultados de partida. Motiva cada una de las decisiones tomadas. Describe cómo se han evaluado los resultados, si se han empleado otras imágenes tomadas por el estudiante y si es así cómo han cambiado los resultados con respecto a los resultados del fichero “EJEMPLO_PRACTICA6.JPG”. Proporciona el resultado obtenido sobre la imagen “EJEMPLO_PRACTICA6.JPG”."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN18c2FEplOF",
        "colab_type": "text"
      },
      "source": [
        "## Conclusiones\n",
        "Discusión final sobre los resultados obtenidos.También son bienvenidos los comentarios que quieras hacer sobre cualquier aspecto del curso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDP_WF5RplOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}